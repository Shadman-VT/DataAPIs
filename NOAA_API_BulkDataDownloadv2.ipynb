{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9be1c47b-482d-4932-ab07-067083806100",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8638610 20120101 20130101 water_level NAVD\n",
      "###############################\n"
     ]
    }
   ],
   "source": [
    "### Author: Md Shadman Sakib 5/3/2024; Original Code: Samuel Daramola; CoRAL Lab, Virginia Tech\n",
    "### information: https://api.tidesandcurrents.noaa.gov/api/prod/#products\n",
    "### 6 min data can be downloaded for 30 days at a stretch, so a sperate function has to be written to recurrently download a year worth of data.\n",
    "### This function has not been updated yet\n",
    "### function has been developed for observed data and prediction data seperately\n",
    "### A excel containing the required fill will be imported as feeder data into the program. Datum, product description should be changed in that excel\n",
    "### A post-processing code will merge the data into useable format for data analysis. This can be later connected/updated to directly connect the ranking program.\n",
    "### Skipping error text for stations where data is not available.\n",
    "\n",
    "### input: A excel with the station information of NOAA; Standard input file format is = \"G:\\My Drive\\Deflt3D FM Codes - Vtech\\DataDownloadAPIs\\inputfiles\\NOAAStationInfoStormStandardInFile.xlsx\"\n",
    "### output: An excel for each station that was listed in the input excel. The name of each of the excel is as per the code assigned to it\n",
    "\n",
    "import pandas as pd\n",
    "from noaa_coops import Station\n",
    "import os\n",
    "\n",
    "#-------------------------------FUNCTION START--------------------------------------------------------------#\n",
    "def fetch_observed(station_id, begin_date, end_date, product, datum):\n",
    "    station = Station(id=station_id)\n",
    "    df_observed = station.get_data(\n",
    "        begin_date=begin_date,\n",
    "        end_date=end_date,\n",
    "        product=product,\n",
    "        datum=datum,\n",
    "        units=\"metric\",\n",
    "        time_zone=\"gmt\") \n",
    "    return df_observed\n",
    "\n",
    "\n",
    "def fetch_prediction(station_id, begin_date, end_date, datum):\n",
    "    station = Station(id=station_id)\n",
    "    df_prediction = station.get_data(\n",
    "        begin_date=begin_date,\n",
    "        end_date=end_date,\n",
    "        product=\"predictions\",\n",
    "        datum=datum,\n",
    "        units=\"metric\",\n",
    "        time_zone=\"gmt\")\n",
    "    return df_prediction\n",
    "\n",
    "#-------------------------------FUNCTION END--------------------------------------------------------------#\n",
    "#---------------------------------------------------------------------------------------------------------#\n",
    "#-------------------------------INPUT START---------------------------------------------------------------#\n",
    "### input file has specific format. For example visit: \"G:\\My Drive\\Deflt3D FM Codes - Vtech\\DataDownloadAPIs\\inputfiles\\NOAAStationInfoStormStandardInFile.xlsx\"\n",
    "station_info=pd.read_excel(r\"G:\\My Drive\\Deflt3D FM Codes - Vtech\\DataDownloadAPIs\\NOAA\\inputfiles\\NOAAStationInfoISandy2012 - Copy.xlsx\").astype(str) #converts the dataframe into strings\n",
    "folder_path=r'G:\\My Drive\\Deflt3D FM Codes - Vtech\\DataDownloadAPIs\\NOAA\\outputfiles\\2012Full6min'\n",
    "\n",
    "#-------------------------------INPUT END-----------------------------------------------------------------#\n",
    "#---------------------------------------------------------------------------------------------------------#\n",
    "#-------------------------------DATA PROCESSING START-----------------------------------------------------#\n",
    "\n",
    "for i in range(len(station_info)):\n",
    "    station_id=station_info['station'][i][-7:] # extracting the station id\n",
    "    begin_date=station_info['begin_date'][i]\n",
    "    end_date=station_info['end_date'][i]\n",
    "    product=station_info['product'][i]\n",
    "    datum=station_info['datum'][i]\n",
    "\n",
    "\n",
    "    filename=station_info['ID'][i]+'.csv'\n",
    "\n",
    "    print(station_id, begin_date, end_date, product, datum)\n",
    "    try:\n",
    "        df_observed=fetch_observed(station_id, begin_date, end_date, product, datum)\n",
    "        df_prediction=fetch_prediction(station_id, begin_date, end_date, datum)\n",
    "        #print(df_observed)\n",
    "        print('###############################')\n",
    "    except Exception as e:\n",
    "        print(\"ERROR: Data not available for this interval at Station: \" + station_info['station'][i])\n",
    "        print('###############################')\n",
    "        continue \n",
    "    \n",
    "    # dataframe merging\n",
    "    merged_data = pd.merge(df_observed, df_prediction, left_index=True, right_index=True, suffixes=('_observed (m)', '_predictions (m)'))\n",
    "    # Convert index to string and then split into 'Date' and 'Time' columns\n",
    "    merged_data['Date'], merged_data['Time'] = zip(*merged_data.index.astype(str).str.split(' '))\n",
    "    merged_data = merged_data.reset_index(drop=True)\n",
    "    \n",
    "    # Reorder columns and rename headers, multi index to single index\n",
    "    cols = ['Date', 'Time', 'v_predictions (m)', 'v_observed (m)']\n",
    "    merged_data = merged_data[cols]\n",
    "    merged_data.columns = ['Date', 'Time (GMT)', 'Predictions (m)', 'Waterlevel (m)']\n",
    "\n",
    "    # merging DateTime column into a single column\n",
    "    merged_data['DateTime (GMT)'] = pd.to_datetime(merged_data['Date'] + ' ' + merged_data['Time (GMT)'])\n",
    "    merged_data = merged_data.drop(['Date', 'Time (GMT)'], axis=1)\n",
    "    merged_data = merged_data[['DateTime (GMT)', 'Predictions (m)', 'Waterlevel (m)']]\n",
    "    merged_data['Datum_Info']= datum\n",
    "\n",
    "\n",
    "    # writing\n",
    "    file_path = os.path.join(folder_path, filename)\n",
    "    merged_data.to_csv(file_path, index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2bd038a3-707e-491e-bd7b-af55c852a34e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV files have been combined into one Excel file.\n"
     ]
    }
   ],
   "source": [
    "### Author: Md Shadman Sakib 5/3/2024; Original Code: Samual Daramola; CoRAL Lab, Virginia Tech\n",
    "### input: The path were all the input csv are located.\n",
    "### output: creates one excel with multiple sheets each representing a different station. This is the input excel for the calibration file.\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "#-------------------------------INPUT START---------------------------------------------------------------#\n",
    "folder_path = r'G:\\My Drive\\Deflt3D FM Codes - Vtech\\DataDownloadAPIs\\NOAA\\outputfiles\\Isabel2003_6min'\n",
    "output_file = 'combined_excel_isabel_01082003_01102003.xlsx'\n",
    "#-------------------------------INPUT END---------------------------------------------------------------#\n",
    "#-------------------------------DATA PROCESSING START-----------------------------------------------------#\n",
    "\n",
    "with pd.ExcelWriter(output_file, engine='openpyxl') as writer:\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith('.csv'):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            df = pd.read_csv(file_path)\n",
    "\n",
    "            # Write the data to a new sheet in the combined file\n",
    "            # Sheet name is set as the filename without the extension\n",
    "            df.to_excel(writer, sheet_name=os.path.splitext(filename)[0], index=False)\n",
    "            \n",
    "print('CSV files have been combined into one Excel file.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20ca49c2-6242-47bb-91e6-77deda20a767",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DateTime (GMT)</th>\n",
       "      <th>Predictions (m)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012-10-15 00:00:00</td>\n",
       "      <td>0.460660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-10-15 00:06:00</td>\n",
       "      <td>0.447518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012-10-15 00:12:00</td>\n",
       "      <td>0.433062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012-10-15 00:18:00</td>\n",
       "      <td>0.417370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012-10-15 00:24:00</td>\n",
       "      <td>0.400485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7436</th>\n",
       "      <td>2012-11-14 23:36:00</td>\n",
       "      <td>0.417864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7437</th>\n",
       "      <td>2012-11-14 23:42:00</td>\n",
       "      <td>0.428600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7438</th>\n",
       "      <td>2012-11-14 23:48:00</td>\n",
       "      <td>0.437891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7439</th>\n",
       "      <td>2012-11-14 23:54:00</td>\n",
       "      <td>0.445742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7440</th>\n",
       "      <td>2012-11-15 00:00:00</td>\n",
       "      <td>0.452177</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7441 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           DateTime (GMT)  Predictions (m)\n",
       "0     2012-10-15 00:00:00         0.460660\n",
       "1     2012-10-15 00:06:00         0.447518\n",
       "2     2012-10-15 00:12:00         0.433062\n",
       "3     2012-10-15 00:18:00         0.417370\n",
       "4     2012-10-15 00:24:00         0.400485\n",
       "...                   ...              ...\n",
       "7436  2012-11-14 23:36:00         0.417864\n",
       "7437  2012-11-14 23:42:00         0.428600\n",
       "7438  2012-11-14 23:48:00         0.437891\n",
       "7439  2012-11-14 23:54:00         0.445742\n",
       "7440  2012-11-15 00:00:00         0.452177\n",
       "\n",
       "[7441 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d892783-9695-4754-9765-32acae965f92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb4faf8-85ec-4571-8279-6f459fa72e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01352683-5daa-4e85-9597-c420f6c6d283",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ed81dc-ad22-41ca-b48c-362b4afdf75f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
