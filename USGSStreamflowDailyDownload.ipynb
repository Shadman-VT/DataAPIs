{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c15bb0dd-5e68-4c72-8229-e77c4535a38c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading USGS Observation Data for 02037500\n",
      "Downloaded Successfully and saved as 02037500.txt\n",
      "\n",
      "Downloading USGS Observation Data for 01674500\n",
      "Downloaded Successfully and saved as 01674500.txt\n",
      "\n",
      "Downloading USGS Observation Data for 01673000\n",
      "Downloaded Successfully and saved as 01673000.txt\n",
      "\n",
      "Downloading USGS Observation Data for 01668000\n",
      "Downloaded Successfully and saved as 01668000.txt\n",
      "\n",
      "Downloading USGS Observation Data for 01646500\n",
      "Downloaded Successfully and saved as 01646500.txt\n",
      "\n",
      "Downloading USGS Observation Data for 01594440\n",
      "Downloaded Successfully and saved as 01594440.txt\n",
      "\n",
      "Downloading USGS Observation Data for 01578310\n",
      "Downloaded Successfully and saved as 01578310.txt\n",
      "\n",
      "Downloading USGS Observation Data for 01491000\n",
      "Downloaded Successfully and saved as 01491000.txt\n",
      "\n",
      "Downloading USGS Observation Data for 01669520\n",
      "Downloaded Successfully and saved as 01669520.txt\n",
      "\n",
      "Downloading USGS Observation Data for 01649500\n",
      "Downloaded Successfully and saved as 01649500.txt\n"
     ]
    }
   ],
   "source": [
    "### Md Shadman Sakib\n",
    "### Downloads USGS data and saves it as a text file.\n",
    "### to be done: create a system to take in and update the extracting based on the dates, just like NOAA\n",
    "\n",
    "import os, sys, stat\n",
    "import pandas as pd\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "from datetime import date\n",
    "import numpy as np\n",
    "import requests\n",
    "\n",
    "'''\n",
    "CPBModel:\n",
    "James River Near Richmond, VA - 02037500\n",
    "Mattaponi River Near Beulahville, VA - 01674500\n",
    "Pamunkey River Near Hanover, VA - 01673000\n",
    "Rappahannock River Near Fredericksburg, VA - 01668000\n",
    "Potomac River Near Wash, DC Little Falls Pump Sta - 01646500\n",
    "Patuxent River Near Bowie, MD - 01594440\n",
    "Susquehanna River at Conowingo, MD - 01578310\n",
    "Choptank River Near Greensboro, MD - 01491000\n",
    "Dragon Swamp at Mascot, VA - 01669520\n",
    "Northeast Branch Anacostia River at Riverdale, MD - 01649500\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "# Specify the USGS IDs to be downloaded\n",
    "USGS_ID_list = [\"02037500\", \"01674500\", \"01673000\", \"01668000\", \"01646500\", \"01594440\", \"01578310\", \"01491000\", \"01669520\", \"01649500\"]\n",
    "\n",
    "# Specify the begin and end date of data\n",
    "begin_date = \"2001-01-01\" # yyyy-mm-day\n",
    "end_date = \"2021-01-01\"\n",
    "\n",
    "# Specify download directory\n",
    "download_dir = \"../USGS_2012_Daily/\"\n",
    "\n",
    "if not os.path.exists(download_dir):\n",
    "    os.makedirs(download_dir)\n",
    "\n",
    "for usgs_site_no in USGS_ID_list:\n",
    "    print(\"\\nDownloading USGS Observation Data for {}\".format(usgs_site_no))\n",
    "    site_no = \"{}\".format(usgs_site_no+'.txt', \"txt\")\n",
    "    url = \"https://waterdata.usgs.gov/nwis/dv?cb_00060=on&format=rdb&site_no={}&referred_module=sw&period=&begin_date={}&end_date={}\".format(usgs_site_no, begin_date, end_date)\n",
    "    r = requests.get(url, allow_redirects=True)\n",
    "    open(os.path.join(download_dir, site_no), 'wb').write(r.content)\n",
    "    print(\"Downloaded Successfully and saved as {}\".format(site_no))\n",
    "    #print(\"\\nNow Copying the files to a Temporary Directory!\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8de4de2-0c22-4875-bf91-39c4b2e8e58f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: G:\\My Drive\\Deflt3D FM Codes - Vtech\\DataDownloadAPIs\\USGS_2012_Daily\n",
      "Changed directory to: G:\\My Drive\\Deflt3D FM Codes - Vtech\\DataDownloadAPIs\\USGS_2012_Daily\n",
      "\n",
      "Reading  02037500.txt  File\n",
      "Starting line for this file is from line number # 26\n",
      "Created the flow data list for  02037500.csv\n",
      "Created the date dataframe from  2001-01-01  to  2021-01-01\n",
      "Checking the length of the flow data list and date window!\n",
      "The length of flow data list is  7306\n",
      "The length of date window is  7306\n",
      "----> 02037500 214.0 2\n",
      "The CSV Time Series for  02037500  has been created!\n",
      "\n",
      "\n",
      "Reading  01674500.txt  File\n",
      "Starting line for this file is from line number # 26\n",
      "Created the flow data list for  01674500.csv\n",
      "Created the date dataframe from  2001-01-01  to  2021-01-01\n",
      "Checking the length of the flow data list and date window!\n",
      "The length of flow data list is  7306\n",
      "The length of date window is  7306\n",
      "----> 01674500 15.0 2\n",
      "The CSV Time Series for  01674500  has been created!\n",
      "\n",
      "\n",
      "Reading  01673000.txt  File\n",
      "Starting line for this file is from line number # 26\n",
      "Created the flow data list for  01673000.csv\n",
      "Created the date dataframe from  2001-01-01  to  2021-01-01\n",
      "Checking the length of the flow data list and date window!\n",
      "The length of flow data list is  7306\n",
      "The length of date window is  7306\n",
      "----> 01673000 26.0 2\n",
      "The CSV Time Series for  01673000  has been created!\n",
      "\n",
      "\n",
      "Reading  01668000.txt  File\n",
      "Starting line for this file is from line number # 26\n",
      "Created the flow data list for  01668000.csv\n",
      "Created the date dataframe from  2001-01-01  to  2021-01-01\n",
      "Checking the length of the flow data list and date window!\n",
      "The length of flow data list is  7306\n",
      "The length of date window is  7306\n",
      "----> 01668000 52.0 2\n",
      "The CSV Time Series for  01668000  has been created!\n",
      "\n",
      "\n",
      "Reading  01646500.txt  File\n",
      "Starting line for this file is from line number # 26\n",
      "Created the flow data list for  01646500.csv\n",
      "Created the date dataframe from  2001-01-01  to  2021-01-01\n",
      "Checking the length of the flow data list and date window!\n",
      "The length of flow data list is  7306\n",
      "The length of date window is  7306\n",
      "----> 01646500 348.0 2\n",
      "The CSV Time Series for  01646500  has been created!\n",
      "\n",
      "\n",
      "Reading  01594440.txt  File\n",
      "Starting line for this file is from line number # 26\n",
      "Created the flow data list for  01594440.csv\n",
      "Created the date dataframe from  2001-01-01  to  2021-01-01\n",
      "Checking the length of the flow data list and date window!\n",
      "The length of flow data list is  7306\n",
      "The length of date window is  7306\n",
      "----> 01594440 12.0 2\n",
      "The CSV Time Series for  01594440  has been created!\n",
      "\n",
      "\n",
      "Reading  01578310.txt  File\n",
      "Starting line for this file is from line number # 26\n",
      "Created the flow data list for  01578310.csv\n",
      "Created the date dataframe from  2001-01-01  to  2021-01-01\n",
      "Checking the length of the flow data list and date window!\n",
      "The length of flow data list is  7306\n",
      "The length of date window is  7306\n",
      "----> 01578310 1200.0 2\n",
      "The CSV Time Series for  01578310  has been created!\n",
      "\n",
      "\n",
      "Reading  01491000.txt  File\n",
      "Starting line for this file is from line number # 26\n",
      "Created the flow data list for  01491000.csv\n",
      "Created the date dataframe from  2001-01-01  to  2021-01-01\n",
      "Checking the length of the flow data list and date window!\n",
      "The length of flow data list is  7306\n",
      "The length of date window is  7306\n",
      "----> 01491000 5.0 2\n",
      "The CSV Time Series for  01491000  has been created!\n",
      "\n",
      "\n",
      "Reading  01669520.txt  File\n",
      "Starting line for this file is from line number # 26\n",
      "Created the flow data list for  01669520.csv\n",
      "Created the date dataframe from  2001-01-01  to  2021-01-01\n",
      "Checking the length of the flow data list and date window!\n",
      "The length of flow data list is  7306\n",
      "The length of date window is  7306\n",
      "----> 01669520 3.0 2\n",
      "The CSV Time Series for  01669520  has been created!\n",
      "\n",
      "\n",
      "Reading  01649500.txt  File\n",
      "Starting line for this file is from line number # 27\n",
      "Created the flow data list for  01649500.csv\n",
      "Created the date dataframe from  2001-01-01  to  2021-01-01\n",
      "Checking the length of the flow data list and date window!\n",
      "The length of flow data list is  7306\n",
      "The length of date window is  7306\n",
      "----> 01649500 3.0 2\n",
      "The CSV Time Series for  01649500  has been created!\n",
      "\n",
      "Successfully Created All Time Series as '.csv' Files From The '.txt' Files:\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "       USGS_Flow(cfs)  USGS_Flow(cms)\n",
      "count     7306.000000     7306.000000\n",
      "mean        99.197265        2.808942\n",
      "std        223.088626        6.317211\n",
      "min          3.130000        0.090000\n",
      "25%         23.800000        0.670000\n",
      "50%         42.400000        1.200000\n",
      "75%         79.600000        2.250000\n",
      "max       4320.000000      122.330000\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "from datetime import datetime, date\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.dates import DateFormatter\n",
    "\n",
    "# Get the current working directory\n",
    "pwd = os.getcwd()\n",
    "print(\"Current working directory:\", pwd)\n",
    "\n",
    "# Specify the location of input USGS text file that contains the data\n",
    "path_inputs = \"../USGS_2012_Daily/\"\n",
    "dir_out = \"../USGS_2012_Daily_CSV/\"\n",
    "\n",
    "# Check if the input directory exists\n",
    "if not os.path.exists(path_inputs):\n",
    "    raise FileNotFoundError(f\"Input directory {path_inputs} does not exist\")\n",
    "\n",
    "# Create output directory if it does not exist\n",
    "if not os.path.exists(dir_out):\n",
    "    os.makedirs(dir_out)\n",
    "\n",
    "# Defining a function to get the starting line number of USGS data\n",
    "lookup_start = \"WARNING\"\n",
    "lookup_end = \"agency_cd\"\n",
    "\n",
    "def get_line_number(filename):\n",
    "    \"\"\"In a file, get the line number based on a given string\"\"\"\n",
    "    with open(filename) as myFile:\n",
    "        for num, line in enumerate(myFile, 1):\n",
    "            if lookup_start in line:\n",
    "                starting_line = num\n",
    "            if lookup_end in line:\n",
    "                ending_line = num\n",
    "    return starting_line, ending_line\n",
    "\n",
    "# Change to the input directory\n",
    "os.chdir(path_inputs)\n",
    "print(\"Changed directory to:\", os.getcwd())\n",
    "\n",
    "for filename in os.listdir():\n",
    "    if filename.endswith('.txt'):\n",
    "        # Check if file exists before processing\n",
    "        file_path = os.path.join(path_inputs, filename)\n",
    "        if not os.path.isfile(file_path):\n",
    "            print(f\"File {file_path} not found. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        # Reading the text files using pandas\n",
    "        print(\"\\nReading \", filename, \" File\")\n",
    "        start_line, End_line = get_line_number(file_path)\n",
    "        print(\"Starting line for this file is from line number #\", int(End_line + 1))\n",
    "\n",
    "        df_txt = pd.read_csv(file_path, sep=\"\\t\", header=None, skiprows=list(range(End_line + 1)))\n",
    "        df_txt.fillna(method='ffill', inplace=True)\n",
    "\n",
    "        # getting the value corresponding to the Datetime\n",
    "        date_list = list()\n",
    "        flow_list = list()\n",
    "\n",
    "        for key, value in df_txt.iterrows():\n",
    "            file_name = \"{}{}\".format(\"0\", str(value[1]))\n",
    "            file_ext = \".csv\"\n",
    "            new_name = \"{}{}\".format(file_name, file_ext)\n",
    "            Title = \"Plot of Observed Data for USGS ID {}\".format(file_name)\n",
    "            fig_name = '{}{}'.format(file_name, \".png\")\n",
    "            date_list.append(str(value[2]))\n",
    "            if str(value[4]) == \"nan\":\n",
    "                flow_list.append(value[7])\n",
    "            else:\n",
    "                flow_list.append(value[4])\n",
    "        print(\"Created the flow data list for \", new_name)\n",
    "\n",
    "        # Creating the dataframe\n",
    "        df = pd.DataFrame(date_list, columns=['Date'])\n",
    "        df = df.set_index('Date')\n",
    "        start_date = date_list[0]\n",
    "        end_date = date_list[-1]\n",
    "        print(\"Created the date dataframe from \", start_date, \" to \", end_date)\n",
    "        print(\"Checking the length of the flow data list and date window!\")\n",
    "        print(\"The length of flow data list is \", len(flow_list))\n",
    "        print(\"The length of date window is \", len(date_list))\n",
    "\n",
    "        if len(date_list) != len(flow_list):\n",
    "            raise ValueError(\"Mismatch found! Stopping the program! Please take care of missing data first\")\n",
    "            sys.exit()\n",
    "        else:\n",
    "            df[\"USGS_Flow(cfs)\"] = flow_list\n",
    "            df[\"USGS_Flow(cms)\"] = np.round(np.array(flow_list) * 0.028316831998814504, 2)\n",
    "            print(\"----> \" + file_name, np.round(np.average(np.array(flow_list) * 0.028316831998814504)), 2)\n",
    "            del flow_list\n",
    "            df.to_csv(os.path.join(dir_out, new_name), index=True)\n",
    "        print(\"The CSV Time Series for \", file_name, \" has been created!\\n\")\n",
    "\n",
    "# Change back to the original directory\n",
    "os.chdir(pwd)\n",
    "print(\"Successfully Created All Time Series as '.csv' Files From The '.txt' Files:\")\n",
    "print(\"+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\")\n",
    "print(df.describe())\n",
    "print(\"+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "814f9257-ee75-4b7a-8662-ac1399dee61b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94.84934706267484"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.average(flow_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87368010-b9cb-4cbe-ac66-945c9750716a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
